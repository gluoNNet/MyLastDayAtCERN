{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/knovotny/GluoNNet/Webfest2019/descriptions_18_2.csv\", names=['Name','Event','title','description'],header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=str(text).lower()\n",
    "    \n",
    "    #text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)\",\" \",text)\n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 4813\n",
      "Number of edges: 14562\n",
      "Average degree:   6.0511\n"
     ]
    }
   ],
   "source": [
    "#df.head()\n",
    "#df.size\n",
    "df['Name']=df['Name'].str.replace(\"{comma}\",\",\")\n",
    "df['description_2']=df['title']+df['description']\n",
    "df['description'] = df['description_2'].apply(lambda x:pre_process(x))\n",
    "#get the text column \n",
    "docs=df['description'].tolist()\n",
    "    #create a vocabulary of words, \n",
    "    #ignore words that appear in 10% of documents, \n",
    "    #eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.05,stop_words='english')\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "for name, group in df.groupby(['Name']):\n",
    "    G.add_node(name,bipartite=0)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    # you only needs to do this once, this is a mapping of index to \n",
    "    feature_names=cv.get_feature_names()\n",
    " #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform(group['description']))\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    " \n",
    "    #extract only the top n; n here is 100\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    for k in keywords:\n",
    "       # print(k,keywords[k])\n",
    "        G.add_node(k,bipartite=1)\n",
    "        G.add_edge(name,k,weight=keywords[k])\n",
    "print(nx.info(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnaf\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Dal Pra, Stefano'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Falabella, Antonio'\n",
      "\t 'Fattibene, Enrico'\n",
      "\t 'Fornari, Federico'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'MICHELOTTO, DIEGO'\n",
      "\t 'Martelli, Barbara'\n",
      "\t 'Spiga, Daniele'\n",
      "\t 'Valassi, Andrea'\n",
      "\t 'Viola, Fabio'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, Luca\n",
      "\t dell'Agnello, luca\n",
      "infn\n",
      "\t 'Andreetto, Paolo'\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Chierici, Andrea'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Costa, Fulvia'\n",
      "\t 'Crescente, Alberto'\n",
      "\t 'Dal Pra, Stefano'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Falabella, Antonio'\n",
      "\t 'Fantinel, Sergio'\n",
      "\t 'Fanzago, Federica'\n",
      "\t 'Fattibene, Enrico'\n",
      "\t 'Fornari, Federico'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'MICHELOTTO, DIEGO'\n",
      "\t 'Martelli, Barbara'\n",
      "\t 'Mazzon, Paolo Emilio'\n",
      "\t 'Menguzzato, Matteo'\n",
      "\t 'Michelotto, Diego'\n",
      "\t 'Sella, Giampietro'\n",
      "\t 'Sgaravatto, Massimo'\n",
      "\t 'Spiga, Daniele'\n",
      "\t 'Traldi, Sergio'\n",
      "\t 'Verlato, Marco'\n",
      "\t 'Viola, Fabio'\n",
      "\t 'Viola, Salvatore'\n",
      "\t 'Zanetti, Marco'\n",
      "\t 'Zangrando, Lisa'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, Luca\n",
      "\t dell'Agnello, luca\n",
      "extension\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Dal Pra, Stefano'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Spiga, Daniele'\n",
      "\t 'Tunka-Rex Collaboration'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "prace\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Dal Pra, Stefano'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Spiga, Daniele'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "bologna\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Dal Pra, Stefano'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Spiga, Daniele'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "knl\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bonacorsi, Daniele'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Cho, Kihyeon'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'De Salvo, Alessandro'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Mun, Myeong-Hwan'\n",
      "\t 'Yeo, Insung'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "located\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Bozzi, Concezio'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Huang, Qiulan'\n",
      "\t 'Li, Haibo'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "owned\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "marconi\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n",
      "knights\n",
      "\t 'Boccali, Tommaso'\n",
      "\t 'Ciangottini, Diego'\n",
      "\t 'Gianelle, Alessio'\n",
      "\t 'Lupato, Anna'\n",
      "\t 'Zani, Stefano'\n",
      "\t dell'Agnello, luca\n"
     ]
    }
   ],
   "source": [
    "for n in G.neighbors(name): \n",
    "    print(n)\n",
    "    for i in G.neighbors(n):\n",
    "        print(\"\\t\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"test_all.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 6));\n",
    "#nx.draw_networkx(G, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 6));\n",
    "#nx.draw_networkx(G, ax=ax, node_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 6));\n",
    "#nx.draw_spring(G, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alist(cv.vocabulary_.keys())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.neighbors(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
